Here’s a first-pass “all the content” markdown file you can shape into a Next.js 15 site. I’ve tried to keep it modular so sections map cleanly to pages / components.

---

# Site Structure

* Home
* About
* Lumera Network
* Consulting
* SmartEdgar
* Open Source
* Writing

  * Investing & Markets
  * AI Engineering & Research
  * History & Math
* Press & Media
* Selected X Posts
* Career Timeline
* Contact

---

# Home / Landing

## Hero

**Title:**
Jeffrey Emanuel

**Tagline (short):**
Entrepreneur, AI engineer, and former hedge fund analyst building the tools that sit between markets and frontier models.

**Tagline (slightly longer):**
Entrepreneur and AI practitioner building Lumera Network, SmartEdgar, and a growing ecosystem of agent-native tools—after a decade as a generalist investor at top long/short hedge funds.

**Location:**
Brooklyn, New York

**Primary CTAs:**

* “Work with me” → Consulting page
* “Read the Nvidia essay” → NVDA article on YouTube Transcript Optimizer
* “Explore my open-source projects” → Open Source page
* “Follow me on X” → @doodlestein

**Hero Blurb (2–3 sentences):**

Jeffrey Emanuel is the founder and CEO of Lumera Network (formerly Pastel Network), a layer‑1 protocol for decentralized storage, AI inference and Web3 infrastructure.([Lumera Protocol][1])

Before diving into crypto and AI full-time, he spent roughly a decade as a generalist long/short equity analyst at firms like Millennium Management and Balyasny Asset Management, focusing on complex, catalyst-driven ideas across sectors.([YouTubeTranscriptOptimizer][2])

Today he splits his time between building Lumera, developing SmartEdgar and other AI-first products, consulting for hedge funds and private equity sponsors on AI strategy, and shipping popular open-source tools for AI coding agents.

**Key “Stats” (hero highlight boxes):**

* ~10 years as a long/short generalist investor at top hedge funds (Millennium, Balyasny, others)([YouTubeTranscriptOptimizer][2])
* Founder & CEO of Lumera Network, a Cosmos‑based L1 for storage + AI inference + interoperability([Lumera Protocol][1])
* Viral author of “The Short Case for Nvidia Stock,” a 12k-word essay that helped catalyze a historic $600B+ drawdown in NVDA’s market cap([YouTubeTranscriptOptimizer][3])
* 8k+ GitHub stars across open-source projects (MCP Agent Mail, Ultimate Bug Scanner, LLM Docs, and others)([GitHub][4])
* 15k+ followers on X as @doodlestein, with multiple posts amplified by leading builders, researchers, and investors([SuperX][5])

---

# About

## One-liner Bio

Entrepreneur and AI engineer building next‑generation infrastructure and tools for agents and investors, after a decade in the trenches of long/short hedge fund investing.

## Short Bio (≈150–180 words)

Jeffrey Emanuel is an entrepreneur, AI practitioner, and former hedge fund analyst. He is the founder and CEO of Lumera Network (formerly Pastel Network), a Cosmos‑based layer‑1 protocol for decentralized storage, AI inference, and cross‑chain interoperability.([Lumera Protocol][1])

Before Lumera, Jeffrey spent roughly ten years as a generalist long/short equity analyst at hedge funds including Millennium Management, Balyasny Asset Management, Tyndall Management, Scoggin Capital, and several smaller long/short partnerships, covering both longs and shorts across sectors.([YouTubeTranscriptOptimizer][2])

He has been studying deep learning since the early 2010s, back when people were still publishing about Restricted Boltzmann Machines in MATLAB and SVMs were competitive on MNIST.([YouTubeTranscriptOptimizer][2])  That blend of quant training, market experience, and hands‑on model work now informs his writing and his products.

In 2025, his 12,000‑word essay “The Short Case for Nvidia Stock” went viral and was widely cited as a contributor to a historic one‑day, $600B+ drawdown in Nvidia’s market cap, leading to global press coverage and intensive consulting work with hedge funds and family offices.([YouTubeTranscriptOptimizer][3])

Today Jeffrey focuses on three things: building Lumera Network, developing tools like SmartEdgar and MCP Agent Mail for AI agents and researchers, and helping sophisticated investors navigate the rapidly shifting AI and compute landscape.

## Long-form Narrative Bio

### Early Academic Background

* Studied mathematics at Reed College (BA, Mathematics, 2001–2005).([Jeffrey Emanuel][6])
* Developed an early interest in the intersection of rigorous quantitative reasoning, computer science, and real‑world systems—foundations that later fed into both his hedge fund career and his work in AI.

### Finance & Hedge Fund Years

Across roughly a decade in public markets, Jeffrey worked as a generalist long/short equity analyst at several hedge funds:

* **Tyndall Management** – Generalist (Oct 2008 – Jan 2011)
* **Scoggin Capital Management, LP II** – Generalist (Jan 2011 – Aug 2012)
* **EigenValue Partners** – Principal (Dec 2012 – Aug 2015)
* **Dasoma Capital** – Generalist Investor (Jul 2015 – May 2016)
* **Dayah Capital** – Generalist Investor (Jun 2016 – Mar 2018)
* **Millennium Management** – Analyst (Jun 2019 – Jul 2020)
* **Balyasny Asset Management** – Senior Analyst (Aug 2020 – Dec 2021)([Jeffrey Emanuel][6])

His mandate was typically broad: work across sectors, find mispricings on both the long and short side, and build detailed, bottoms‑up models around complex catalysts, structural shifts, and capital allocation dynamics. He twice won the Best Idea award on the Value Investors Club, for both long and short recommendations, signaling a strong track record of differentiated research.([YouTubeTranscriptOptimizer][2])

### Transition into AI & Crypto Infrastructure

Parallel to his investing work, Jeffrey spent years studying deep learning and working with early neural models. By the mid‑2010s and especially post‑Transformer, he was using frontier models daily, both as a user and as a builder of tools around them.([YouTubeTranscriptOptimizer][2])

That expertise eventually converged with crypto infrastructure. As founder and CEO of Pastel Network—now **Lumera Network**, a Cosmos‑based L1—he’s helped steer the protocol from an early NFT‑focused chain to a broader platform for decentralized storage, AI inference, and cross‑chain interoperability.([Lumera Protocol][1])

Lumera’s design centers on a few core beliefs:

* **Data and models should live on open, censorship‑resistant infrastructure.**
* **AI workloads will increasingly need verifiable, decentralized execution.**
* **The future looks like an ecosystem of specialized chains and agents, not a single monolithic platform.**

### Writing, Research, and Market Impact

In January 2025, Jeffrey published **“The Short Case for Nvidia Stock”** on the YouTube Transcript Optimizer blog, a deep dive into how shifting AI economics—particularly the emergence of cost‑efficient models like DeepSeek—might erode Nvidia’s position in the AI hardware stack.([YouTubeTranscriptOptimizer][2])

The essay:

* Argued that the market was overpaying for a narrow interpretation of Nvidia’s moat.
* Highlighted the strategic implications of models delivering GPT‑4‑level performance at a fraction of the cost.([Bankless][7])
* Connected AI scaling laws, inference economics, and GPU supply to eventual earnings dynamics.

The post went viral after being widely shared on X and in investing circles, leading to extensive coverage in outlets such as MarketWatch, Mint, Slashdot, Diginomica and various newsletters that framed him as the blogger who “helped spark Nvidia’s $600 billion stock collapse.”([MarketWatch][8])

Following the essay, Jeffrey began advising hedge funds and family offices—often at four‑figure hourly rates—on AI and compute strategy, risk to incumbents, and how to underwrite the next decade of AI equity returns.([mint][9])

### Current Focus

* Scaling **Lumera Network** as a foundational layer for decentralized storage, AI inference, and interchain composability.([Lumera Protocol][1])
* Developing **SmartEdgar**, a modern SEC EDGAR workflow and research platform with an MCP server and rich document processing capabilities designed for AI agents.([Glama – MCP Hosting Platform][10])
* Shipping and maintaining **agent‑native tools** like MCP Agent Mail and Ultimate Bug Scanner.([GitHub][11])
* Writing essays on AI, markets, and mathematical ideas—often blending mechanistic reasoning about models with practical implications for investors and builders.([YouTubeTranscriptOptimizer][12])

---

# Lumera Network

## One-sentence overview

Lumera Network (formerly Pastel Network) is a Cosmos‑based layer‑1 blockchain providing decentralized storage, AI solutions, and cross‑chain interoperability for Web3 builders.([Lumera Protocol][1])

## Positioning paragraph

Lumera Protocol is what you get if you take decentralized storage seriously, treat AI inference as a first‑class on‑chain citizen, and design for interchain interoperability from day one. It offers builders a scalable base layer for storing and validating digital assets, running AI‑powered services, and bridging value and data across ecosystems like Ethereum and Solana.([Lumera Protocol][1])

## Core pillars (for feature cards)

1. **Decentralized Storage (Cascade)**

   * Long‑term, redundant storage for NFTs, documents, and arbitrary blobs.
   * Designed for permanence and high availability rather than “cheap but flaky” storage.([Lumera Protocol][1])

2. **AI & LLM Services (Sense + Inference)**

   * On‑chain AI authenticity verification for digital assets.
   * Infrastructure for deploying localized LLMs and machine‑learning models for real‑time analysis and decisioning.([Lumera Protocol][1])

3. **Cross‑Chain Interoperability**

   * Open APIs and bridging infrastructure connecting Lumera to major ecosystems.
   * Enables dApps to interact with Ethereum, Solana, and others without siloing liquidity or data.([Lumera Protocol][1])

4. **Security & Permissionlessness**

   * Sovereign L1 built on the Cosmos SDK.
   * Emphasis on validator decentralization and robust consensus mechanisms.([Lumera Protocol][1])

## Jeffrey’s role / story

Copy for a personal “founder story” block:

> I started Lumera Network (originally Pastel Network) with a simple idea: if AI is going to sit underneath everything, the infrastructure it runs on shouldn’t be fragile, centralized, or closed. Coming out of long/short investing, I had seen too many stories where critical dependencies were opaque—whether that was balance‑sheet leverage, supply‑chain risk, or one vendor owning an entire stack. Lumera is my attempt to build the opposite of that: a protocol where storage, compute, and interoperability are openly verifiable, and where builders can treat AI as a composable primitive, not a black box API.

## Quick Timeline Snippet (for a timeline component)

* **2018–2021:** Pastel Network launches as an NFT‑oriented chain with specialized infrastructure for digital art provenance and storage.
* **2024–2025:** Pastel 2.0 transition toward a Cosmos‑based sovereign chain focused on storage + AI.([Lumera Protocol][1])
* **2025:** Rebrand to **Lumera Protocol**, launch of LUME token, mainnet, and deeper cross‑chain integrations.([Lumera Protocol][1])

---

# Consulting – AI, Markets, and Automation

## Audience

Primarily:

* Long/short hedge funds
* Multi‑manager platforms
* Private equity funds
* Family offices and large allocators

## Value Proposition (headline + blurb)

**Headline:**
AI strategy and workflow design from someone who has actually sat in your seat.

**Blurb:**
Most AI “strategy” decks are either vague futurism or vendor sales pitches. Jeffrey offers something different: deep hands‑on experience with frontier models and agentic workflows, grounded in the realities of P&L, risk limits, and LP reporting. He helps funds translate AI capabilities into concrete investments, risk scenarios, and internal tools—without getting lost in buzzwords.

## What Jeffrey does

### 1. Market & Risk Analysis

* Deep dives on AI‑sensitive names (semis, hyperscalers, model labs, robotics, infra).
* Scenario analysis around shifts like DeepSeek’s cost structure, chain‑of‑thought inference scaling, and new model architectures.([Bankless][7])
* Guidance on where Nvidia‑style over‑earning risk might show up elsewhere in the stack.

### 2. Workflow & Automation Design

* Mapping out where LLMs and agents can safely sit inside an investment process: idea generation, research synthesis, model‑building, risk checks, operations.
* Designing agentic pipelines for tasks like:

  * Processing large volumes of transcripts, filings, and alternative data.
  * Automated EDGAR workflows via SmartEdgar.
  * Code‑driven research tooling that doesn’t drown the team in technical debt.

### 3. Staff Enablement

* Playbooks for analysts and PMs on using tools like Claude Code, GPT‑5 Codex, Gemini CLI, and custom MCP servers effectively (and safely).([GitHub][11])
* Training on prompt design, agent orchestration, and integrating AI into Excel / Python / internal dashboards.

### 4. Boardroom & IC Sessions

* One‑off or recurring sessions with investment committees and boards on the state of AI: what’s real, what’s hype, and what the second‑order effects look like over 3–10 years.
* Tailored discussions on how AI might reshape specific sectors—healthcare, legal services, enterprise software, industrials, etc.

## Example Engagement Types

* **“DeepSeek & the AI cost reset”**: Full‑day workshop for a multi‑manager platform analyzing how radically cheaper inference changes hyperscaler and semi economics, and how to price that into names.([Bankless][7])
* **“Upgrading your research stack”**: Multi‑week build‑out of an internal agentic research pipeline (SmartEdgar + MCP Agent Mail + custom tools) with human‑in‑the‑loop controls.([Glama – MCP Hosting Platform][10])
* **“AI risk & opportunity for a PE portfolio”**: Portfolio review for a PE firm, highlighting where AI augments margins, where it compresses them, and which portfolio companies should be aggressively leaning in.

## How to Work Together (Process snippet)

1. **Intro call** – Understand mandate, strategy, and current workflows.
2. **Scoping doc** – Jeffrey drafts a short, concrete engagement plan.
3. **Deep work phase** – Mixture of calls, async memos, and hands‑on buildout (where relevant).
4. **Deliverables** – Written materials, demos, code, or playbooks tailored to the fund’s team.
5. **Follow‑up** – Optional quarterly check‑ins as the AI landscape shifts.

---

# SmartEdgar

## One‑sentence overview

SmartEdgar is a modern SEC EDGAR ingestion, processing, and research platform built for AI agents and human analysts, with an integrated MCP server and heavy‑duty document tooling.([Glama – MCP Hosting Platform][10])

## Positioning

Legacy EDGAR tools were built for a world where a human opened a PDF once in a while. SmartEdgar assumes your “reader” is a fleet of AI agents parsing filings at machine speed, cross‑linking them with models, and surfacing anomalies in real time.

## Core capabilities (for feature cards)

* **High‑throughput filing downloader** – Efficiently pulls 10‑K, 10‑Q, 8‑K, S‑1, and XBRL data with rate‑limited, robust scraping.([Glama – MCP Hosting Platform][10])
* **Rich document processing** – Uses a battery of tools (PyMuPDF, XBRL toolchains, PDF parsers, HTML cleaners) to transform messy filings into clean, chunked, agent‑ready text and structured data.([Glama – MCP Hosting Platform][10])
* **MCP server integration** – Exposes search, retrieval, and screening functionality over the Model Context Protocol, so tools like Claude Code, Codex, Gemini CLI, or custom agents can query filings directly.([Glama – MCP Hosting Platform][10])
* **Task‑aware CLI** – Typer‑based CLI for human analysts: run focused queries, screen sectors, or generate prompts for your preferred model.

## Example workflows

* “Show me every 10‑K in the last 3 years where management walked back prior AI capex guidance.”
* “Flag all filings this quarter with unusual language around ‘AI agents’, ‘LLM’, or ‘compute cost optimization’ and summarize the shifts by sector.”
* “For these tickers, pull the last 10 years of risk factor sections and cluster them by emerging themes.”

---

# Open Source Projects

Intro paragraph:

Jeffrey spends a significant chunk of his time building open‑source infrastructure for LLM agents, documentation, and code quality. Below are some of the flagship projects; most live under the `Dicklesworthstone` GitHub account.

---

## MCP Agent Mail

* **Repo:** [https://github.com/Dicklesworthstone/mcp_agent_mail](https://github.com/Dicklesworthstone/mcp_agent_mail) ([GitHub][11])
* **Tagline:** “Like Gmail for your coding agents.”([GitHub][11])

### Elevator pitch

MCP Agent Mail is a mail‑like coordination layer for coding agents, exposed as an HTTP‑only FastMCP server. It gives agents stable identities, inboxes and outboxes, searchable message history, and advisory file reservation “leases” to avoid stomping on each other’s edits.([GitHub][11])

### Key capabilities (bullet list)

* Register temporary‑but‑persistent agent identities.
* Send and receive GitHub‑flavored Markdown messages (with images) between agents and humans.
* Thread and search conversations via a SQLite‑backed index.
* Declare advisory leases on files or globs so agents can coordinate who’s editing what.
* Git‑backed storage for all artifacts so humans can audit every message and change.([GitHub][11])

### Companion App

In addition to the core open‑source server, Jeffrey is building a **commercial companion app**:

* An iOS + automation stack that discovers installed coding agents, wires them to MCP Agent Mail, and manages “message stacks” of instructions to keep swarms of agents aligned with minimal human babysitting.([GitHub][11])

---

## Ultimate Bug Scanner (UBS)

* **Repo:** [https://github.com/Dicklesworthstone/ultimate_bug_scanner](https://github.com/Dicklesworthstone/ultimate_bug_scanner) ([GitHub][4])
* **Tagline:** Industrial‑grade static analysis for all popular programming languages, tuned for AI coding agents.

### Overview

Ultimate Bug Scanner is a meta‑runner that orchestrates language‑specific scanners (JavaScript/TypeScript, Python, Go, Rust, Java, C/C++, Ruby, etc.) and surfaces their findings in a unified, machine‑readable format that plays nicely with agents.([GitHub][4])

### Notable features

* One‑line install script for easy adoption (`curl … | bash`).([GitHub][4])
* Git‑aware scanning modes (`ubs --staged`, `ubs --diff`) to check only what changed—a big deal for agent‑driven workflows.([GitHub][4])
* Strictness profiles (`--profile=strict` vs `--profile=loose`) depending on whether you’re shipping production code or prototyping.([GitHub][4])
* Machine‑readable purity: JSON output on stdout with logs relegated to stderr, so agents can safely parse results.([GitHub][4])

---

## LLM Docs

* **Repo:** [https://github.com/Dicklesworthstone/llm_docs](https://github.com/Dicklesworthstone/llm_docs) ([GitHub][13])

### Elevator pitch

LLM Docs is a fully automated system for ingesting Python package documentation from the web and transforming it into LLM‑friendly formats. It standardizes sprawling, inconsistent docs into compact, high‑signal knowledge bundles that models can actually use.([GitHub][13])

### Highlights

* Discovers popular Python packages and scrapes their documentation.
* Distills docs to remove redundancy and boilerplate, improving accuracy and reducing token usage.
* Outputs formats optimized for multiple LLM providers (Anthropic, OpenAI, Google, Mistral, etc.).([GitHub][13])

---

## LLM Introspective Compression & Metacognition

* **Repo:** [https://github.com/Dicklesworthstone/llm_introspective_compression_and_metacognition](https://github.com/Dicklesworthstone/llm_introspective_compression_and_metacognition) ([GitHub][14])

### Summary

This project proposes a system for **real‑time introspective compression** of transformer internal states: saving and compressing activations and key/value caches into a learned latent manifold that can be stored, inspected, and replayed later.([GitHub][14])

### Why it matters

* Enables “save‑states” of model reasoning, analogous to video game save files.
* Makes backtracking, branch‑and‑bound reasoning, and metacognitive control tractable by reconstructing approximate internal states from compact codes.([GitHub][14])

---

## Model-Guided Research

* **Repo:** [https://github.com/Dicklesworthstone/model_guided_research](https://github.com/Dicklesworthstone/model_guided_research) ([GitHub][15])

### Concept

Model‑Guided Research is a playground for using LLMs to explore advanced mathematical structures (tropical geometry, p‑adic computation, nonstandard analysis, etc.) as potential building blocks for next‑generation AI architectures.([GitHub][15])

It treats LLMs not just as code generators but as partners in theoretical exploration, combining symbolic reasoning, simulation, and code experiments.

---

## Useful Coding Guides for LLMs

* **Repo:** [https://github.com/Dicklesworthstone/useful_coding_guides_for_llms](https://github.com/Dicklesworthstone/useful_coding_guides_for_llms) ([GitHub][16])

### Purpose

A living documentation set for how to build robust, maintainable **Next.js 15** applications and other stacks while collaborating with LLM coding tools. It includes a nearly 1000‑line `NEXTJS15_BEST_PRACTICES.md` guide, implementation checklists, and example interactions with tools like Claude Code.([GitHub][16])

This is effectively the style guide for how Jeffrey prefers large codebases to be structured—the same philosophy that can be applied to this personal site.

---

## Kissinger Thesis Reader

* **Repo:** [https://github.com/Dicklesworthstone/kissinger_undergraduate_thesis](https://github.com/Dicklesworthstone/kissinger_undergraduate_thesis) ([GitHub][17])

### Story

Frustrated by the difficulty of reading Henry Kissinger’s 400‑page undergraduate thesis as a scanned PDF, Jeffrey built a pipeline that cleans, restructures, and presents it in a more readable, “vibe‑coded” format.([GitHub][17])

This project became the anchor for a widely‑shared X post about using AI and tooling to make dense, historical primary sources actually pleasant to read on modern devices.

---

## Other Notable Repos (for cards or a scrolling list)

* **YouTube Transcript Optimizer backend & blog infra** – FastAPI backend and Next.js/Tailwind blog system powering YTO, including posts on building the system itself.([YouTubeTranscriptOptimizer][12])
* **FMD Blog Posts** – Markdown versions of longform essays on AI alignment, prompt injection, tax automation, and more (backing Fix My Documents blog).([GitHub][18])

---

# Writing

## Flagship Essay – The Short Case for Nvidia Stock

* **Title:** The Short Case for Nvidia Stock
* **Link:** [https://youtubetranscriptoptimizer.com/blog/05_the_short_case_for_nvda](https://youtubetranscriptoptimizer.com/blog/05_the_short_case_for_nvda) ([YouTubeTranscriptOptimizer][2])
* **Published:** January 25, 2025
* **Length:** ~12,000 words; ~60‑minute read([YouTubeTranscriptOptimizer][2])

### Summary (for feature card)

A deep dive into how AI scaling laws, emerging models like DeepSeek, and the economics of inference vs. training might derail Nvidia’s extraordinary run. The essay combines detailed technical understanding of large models with public‑equity style modeling and scenario analysis, arguing that the market had over‑priced a narrow, GPU‑centric path for AI.([YouTubeTranscriptOptimizer][2])

### Impact blurb

The essay went viral across X, Reddit, and investing circles, was highlighted by high‑profile investors, and was later cited by outlets like MarketWatch, Slashdot, Mint, and Diginomica as a contributor to the historic $600B+ NVDA drawdown in January 2025.([Slashdot Hardware][19])

---

## YouTube Transcript Optimizer Blog – Selected Posts

**Blog home:** [https://youtubetranscriptoptimizer.com/blog](https://youtubetranscriptoptimizer.com/blog) ([YouTubeTranscriptOptimizer][12])

### 1. The Most Impressive Prediction of All Time (History)

* **Angle:** A historical deep dive into an astonishingly accurate long‑range prediction and what it says about human foresight, evidence, and Bayesian reasoning.([YouTubeTranscriptOptimizer][12])

### 2. What I Learned from Making the Python Backend for YouTube Transcript Optimizer (Web Development)

* Lessons from building a production FastAPI backend for transforming YouTube videos into structured transcripts, documents, and quizzes.
* Covers architecture choices, performance trade‑offs, and how to design for LLM‑driven workloads.([YouTubeTranscriptOptimizer][12])

### 3. Introducing Our New Next.js Blogging System with Tailwind CSS (Web Development)

* Walkthrough of building a modern, fast blogging system with Next.js and Tailwind, optimized for developer ergonomics and content velocity.([YouTubeTranscriptOptimizer][12])

### 4. Next.js GitHub Markdown Blog: A Modern Approach to Technical Blogging (Development)

* Describes a GitHub‑backed content pipeline where Markdown in repos becomes the source of truth for technical blogging, ideal for documentation‑heavy projects.([YouTubeTranscriptOptimizer][12])

---

## Fix My Documents Blog – Selected Posts

**Blog home:** [https://fixmydocuments.com/blog](https://fixmydocuments.com/blog) ([FixMyDocuments][20])

### Investing & Markets

1. **Factor Risk Models and the Hedge Fund Business**

   * Explains what factor models are, why they matter for portfolio construction, and how real hedge funds actually use (and misuse) them.([FixMyDocuments][20])

2. **PPP Loan Fraud: A Data Science Detective Story**

   * Reconstructs the PPP loan program’s fraud dynamics using data analysis, highlighting how simple tools could have caught much of the abuse.([FixMyDocuments][20])

### AI Engineering & Applications

3. **Making Complex Code Changes with Claude Code and Cursor**

   * Practical playbook for using agentic coding tools to refactor and extend large codebases without losing control.([FixMyDocuments][20])

4. **Protecting Against AI Prompt Injection Attacks with Innoculation**

   * Presents a concrete system prompt and strategies for defending AI systems against prompt injection and jailbreaking attacks.([FixMyDocuments][20])

5. **Engineering the Mindmap Generator: Marshalling LLMs for Hierarchical Document Analysis**

   * Details how to orchestrate LLMs to turn long, messy documents into structured, hierarchical mindmaps—useful for research, legal work, and more.([FixMyDocuments][20])

6. **Acting as Claude’s Research Helper in AI**

   * A very long (over two hours to read) exploration of how advanced mathematics might illuminate LLM behavior and inspire new architectures; essentially a research program in essay form.([FixMyDocuments][20])

### AI & Society / Alignment

7. **Some Thoughts on AI Alignment: Using AI to Control AI**

   * Surveys creative proposals for aligning advanced AI, with an emphasis on using AI systems themselves as part of the control stack.([FixMyDocuments][20])

### History of Mathematics

8. **The Lessons of Hermann Grassmann and the Nature of Abstractions**

   * Profiles one of the most under‑appreciated mathematicians in history and connects his work on abstraction to modern AI and representation learning.([FixMyDocuments][20])

---

## GitHub Essays / Research Artifacts

Some “repos” are really essays packaged as code projects:

* **Real‑Time Introspective Compression for Transformers** (in `llm_introspective_compression_and_metacognition`) – a structured research proposal on compression of internal transformer states.([GitHub][14])
* **Model-Guided Research** – outlines a program for using LLMs to explore exotic math (ultrametric spaces, tropical geometry, surreal numbers) as candidate building blocks for new architectures.([GitHub][15])

These can be featured as “Research Notes” on the writing page.

---

# Press & Media

## Representative Coverage (for logos + blurbs)

* **MarketWatch** – Profiled Jeffrey as “the blogger who helped spark Nvidia’s $600 billion stock collapse,” recounting how his essay spread across X and into Silicon Valley.([MarketWatch][8])
* **Slashdot** – Amplified the MarketWatch story, emphasizing how an independent blogger surfaced risks that many Wall Street firms overlooked.([Slashdot Hardware][19])
* **Mint (India)** – Covered Nvidia’s stock crash and cited Jeffrey’s blog post as one of the drivers behind Wall Street’s reassessment of AI valuations, noting his subsequent advisory calls with hedge funds at $1,000/hour.([mint][9])
* **Diginomica** – Wrote about Jeffrey’s Nvidia essay and the broader DeepSeek‑driven correction, framing it as a cautionary tale about concentration risk and narrative bubbles.([Diginomica][21])
* **Neural Markets / Decisional** – Introduced him as a former hedge fund analyst turned AI practitioner who’s been thinking about deep learning since the early days, and as someone whose work moved markets by trillions of dollars in aggregate.([neuralmarkets.decisional.com][22])

## Podcasts & Interviews

1. **Bankless – “DeepSeek R1 & The Short Case For Nvidia Stock | Jeffrey Emanuel”**

   * **Link:** [https://www.bankless.com/podcast/deepseek-r1-the-short-case-for-nvidia-stock-jeffrey-emanuel](https://www.bankless.com/podcast/deepseek-r1-the-short-case-for-nvidia-stock-jeffrey-emanuel) ([Bankless][7])
   * **Angle:** Discusses DeepSeek’s radically cheaper model, the implications for Nvidia and AI hardware economics, and how his essay interacted with that news flow.

2. **YouTube – “Jeffrey Emanuel: Viral Author of The Short Case for Nvidia Stock”**

   * **Link:** [https://www.youtube.com/watch?v=3x-KxQ4p8J0](https://www.youtube.com/watch?v=3x-KxQ4p8J0) ([YouTube][23])
   * **Angle:** Long‑form conversation about his background, the essay, and how he thinks about markets, AI, and risk.

(You can add timestamps or key topics per episode if you want a more detailed “media” section.)

---

# Selected X Posts / Threads

Rather than embedding every post, highlight a few “concept threads” and link out.

## 1. Vibe‑Coded Reader for Henry Kissinger’s Thesis

* **Post ID:** 1961817172516168098
* **Theme:** Using AI tooling to transform a painful scanned PDF (Kissinger’s 400‑page undergraduate thesis) into a pleasant, phone‑friendly reading experience.([GitHub][17])
* **Related repo:** `kissinger_undergraduate_thesis`

## 2. Python 3.14 and the End of the GIL

* **Post ID:** 1976478297744699771
* **Theme:** Hands‑on story about upgrading a complex codebase to Python 3.14 (with the GIL removed) using AI agents and tools like `uv`, showing how much faster multi‑threaded workloads can become. The thread was widely circulated in the Python and AI communities and cited in coverage about the GIL removal.([X (formerly Twitter)][24])

## 3. DeepSeek OCR and the New Scaling Law

* **Post ID:** 1980282222893535376
* **Theme:** Argues that DeepSeek’s OCR / vision‑token approach implies a new “compression scaling law”: vision tokens as a 10x more efficient representation than text tokens, with profound implications for long‑context models and AI memory. The post was quoted across Reddit, Chinese tech media, and LinkedIn.([Reddit][25])

## 4. Project Organization & SmartEdgar

* **Post ID:** 1956526808397975779
* **Theme:** Discusses how he organizes projects in a data directory (`/data/projects/smartedgar`, `/data/projects/smartedgar_mcp`, etc.) and uses that structure to keep multiple agent‑driven projects manageable.([X (formerly Twitter)][26])

## 5. General AI & Robotics Threads

Additional threads (not listed by ID here) include:

* Why AI and robotics disruption is inevitable and why incumbents often underestimate timeline compression.([LinkedIn][27])
* Reflections on Gemini CLI, OpenAI updates, and how agent ecosystems are evolving.([LinkedIn][28])

---

# Career Timeline

A reusable timeline component can be driven by the following data:

* **Founder & CEO, Lumera Network (formerly Pastel Network)**

  * *Dec 2021 – Present*
  * Building a Cosmos‑based layer‑1 providing decentralized storage, AI solutions, and cross‑chain interoperability.([Jeffrey Emanuel][6])

* **Senior Analyst, Balyasny Asset Management L.P.**

  * *Aug 2020 – Dec 2021*
  * Generalist long/short equity role in a multi‑manager environment.([Jeffrey Emanuel][6])

* **Analyst, Millennium Management**

  * *Jun 2019 – Jul 2020*([Jeffrey Emanuel][6])

* **Generalist Investor, Dayah Capital**

  * *Jun 2016 – Mar 2018*([Jeffrey Emanuel][6])

* **Generalist Investor, Dasoma Capital**

  * *Jul 2015 – May 2016*([Jeffrey Emanuel][6])

* **Principal, EigenValue Partners**

  * *Dec 2012 – Aug 2015*([Jeffrey Emanuel][6])

* **Generalist, Scoggin Capital Management, LP II**

  * *Jan 2011 – Aug 2012*([Jeffrey Emanuel][6])

* **Generalist, Tyndall Management**

  * *Oct 2008 – Jan 2011*([Jeffrey Emanuel][6])

* **Education – Reed College**

  * BA, Mathematics (2001–2005).([Jeffrey Emanuel][6])

---

# Contact & Social

## Contact Section Copy

**Headline:** Get in touch

**Blurb:**
For consulting inquiries, collaboration ideas, or media requests, the best way to reach me is via email. I read everything, though I can’t always respond quickly when deep in build mode.

**Email:**
`jeffreyemanuel@gmail.com`([Jeffrey Emanuel][6])

**Preferred topics:**

* AI & compute strategy for funds and large allocators
* Agent‑native tooling and workflow design
* Collaborations around Lumera Network
* Longform writing, interviews, and podcasts

## Social Links

* **X (Twitter):** [https://x.com/doodlestein](https://x.com/doodlestein) ([X (formerly Twitter)][29])
* **GitHub:** [https://github.com/Dicklesworthstone](https://github.com/Dicklesworthstone) ([GitHub][30])
* **LinkedIn:** [https://www.linkedin.com/in/jeffreyemanuel](https://www.linkedin.com/in/jeffreyemanuel) ([LinkedIn][31])

---

# SEO / Meta Snippets

## Homepage Meta Description

> Jeffrey Emanuel is the founder and CEO of Lumera Network, a Cosmos‑based L1 for decentralized storage and AI inference, and the viral author of “The Short Case for Nvidia Stock.” He builds open‑source tools for AI agents, develops SmartEdgar for SEC research, and advises hedge funds and private equity firms on AI and compute strategy.

## Consulting Page Meta Description

> Advisory work for hedge funds, multi‑manager platforms, and private equity funds at the intersection of AI, markets, and automation—delivered by a former long/short generalist who now builds frontier‑model tooling full‑time.

## Writing Page Meta Description

> Essays and research by Jeffrey Emanuel on AI, markets, and mathematics, including the widely discussed “Short Case for Nvidia Stock,” AI alignment pieces, and deep technical explorations of LLMs.

---

This should be enough raw material to wire up a multi‑page Next.js 15 site with rich content blocks, “stat” components, cards, and timelines. Next step we can do is map this into an explicit page/component structure and then into complete code.

[1]: https://pastel.network/ "Lumera - Revolutionizing Borderless Web3 Infrastructure"
[2]: https://youtubetranscriptoptimizer.com/blog/05_the_short_case_for_nvda "The Short Case for Nvidia Stock | YouTube Transcript Optimizer"
[3]: https://youtubetranscriptoptimizer.com/blog/05_the_short_case_for_nvda?utm_source=chatgpt.com "The Short Case for Nvidia Stock"
[4]: https://github.com/Dicklesworthstone/ultimate_bug_scanner "GitHub - Dicklesworthstone/ultimate_bug_scanner:  Industrial-grade static analysis for all popular programming languages. Catch 1000+ bug patterns before production"
[5]: https://archetype.superx.so/creators/doodlestein?utm_source=chatgpt.com "Jeffrey Emanuel (@doodlestein) X Analytics | SuperX"
[6]: https://www.jeffreyemanuel.com/ "Home | Jeffrey Emanuel"
[7]: https://www.bankless.com/podcast/deepseek-r1-the-short-case-for-nvidia-stock-jeffrey-emanuel "DeepSeek R1 & The Short Case For Nvidia Stock | Jeffrey Emanuel"
[8]: https://www.marketwatch.com/story/the-blogger-who-helped-spark-nvidias-600-billion-stock-collapse-and-a-panic-in-silicon-valley-52aba340?gaa_at=eafs&gaa_n=AWEtsqdbCOzJGfIpOSkUSaV1HwJ6Mei8Y8RDPkrlrj6uRAhbFdw_f3Ta9-XZ&gaa_sig=Cz7W4Ddsy0yrJSxudDSvwyaxoPJ20HoBbr6g7l5JUTWON0b1jEvWj4gqtzf6Szgn83BUDimcgLtDG8V-Ix0YXw%3D%3D&gaa_ts=6920d6f2&utm_source=chatgpt.com "The blogger who helped spark Nvidia's $600 billion stock ..."
[9]: https://www.livemint.com/market/stock-market-news/nvidia-stock-crash-how-a-brooklyn-based-blogger-fueled-the-ai-giants-600-bn-market-collapse-heres-what-report-says-11738580355807.html?utm_source=chatgpt.com "Nvidia stock crash: How a Brooklyn-based blogger fueled the ..."
[10]: https://glama.ai/mcp/servers/%40Dicklesworthstone/mcp_agent_mail/blob/618b12aaf377f08c306e0840db3f03de599ec0ab/third_party_docs/PYTHON_FASTMCP_BEST_PRACTICES.md?utm_source=chatgpt.com "MCP Agent Mail"
[11]: https://github.com/Dicklesworthstone/mcp_agent_mail "GitHub - Dicklesworthstone/mcp_agent_mail: Like gmail for your coding agents. Lets various different agents communicate and coordinate with each other."
[12]: https://youtubetranscriptoptimizer.com/blog "Blog | YouTube Transcript Optimizer"
[13]: https://github.com/Dicklesworthstone/llm_docs "GitHub - Dicklesworthstone/llm_docs: Actual implementation of llm-docs.org project"
[14]: https://github.com/Dicklesworthstone/llm_introspective_compression_and_metacognition "GitHub - Dicklesworthstone/llm_introspective_compression_and_metacognition: A novel approach for transformer model introspection that enables saving, compressing, and manipulating internal thought states for advanced capabilities like reasoning backtracking, latent thought optimization, and metacognitive control."
[15]: https://github.com/Dicklesworthstone/model_guided_research "GitHub - Dicklesworthstone/model_guided_research"
[16]: https://github.com/Dicklesworthstone/useful_coding_guides_for_llms "GitHub - Dicklesworthstone/useful_coding_guides_for_llms"
[17]: https://github.com/Dicklesworthstone/kissinger_undergraduate_thesis?utm_source=chatgpt.com "Dicklesworthstone/kissinger_undergraduate_thesis"
[18]: https://github.com/Dicklesworthstone/fmd_blog_posts "GitHub - Dicklesworthstone/fmd_blog_posts"
[19]: https://hardware.slashdot.org/story/25/02/01/2235213/one-blogger-helped-spark-nvidias-600b-stock-collapse "One Blogger Helped Spark NVIDIA's $600B Stock Collapse - Slashdot"
[20]: https://fixmydocuments.com/blog "Blog | Fix My Documents"
[21]: https://diginomica.com/jeffrey-emanuel-and-lessons-we-should-all-learn-2-trillion-deepseek-ai-market-correction?utm_source=chatgpt.com "Jeffrey Emanuel and the lessons we should all learn from ..."
[22]: https://www.neuralmarkets.decisional.com/p/the-ai-practitioner-that-moved-markets?utm_source=chatgpt.com "The AI practitioner that moved markets by a TRILLION dollars"
[23]: https://www.youtube.com/watch?v=3x-KxQ4p8J0&utm_source=chatgpt.com "Jeffrey Emanuel: Viral Author of The Short Case for Nvidia Stock"
[24]: https://x.com/doodlestein/status/1976478297744699771?utm_source=chatgpt.com "So Python 3.14 finally came out for real yesterday. ..."
[25]: https://www.reddit.com/r/accelerate/comments/1obr236/jeffrey_emanuel_deepseek_just_released_a_pretty/?utm_source=chatgpt.com "Jeffrey Emanuel: \"DeepSeek just released a pretty ..."
[26]: https://x.com/doodlestein/status/1956526808397975779?utm_source=chatgpt.com "Jeffrey Emanuel - doodlestein"
[27]: https://www.linkedin.com/posts/jeffreyemanuel_recently-ive-noticed-people-making-a-big-activity-7369822226763788288-zLhO?utm_source=chatgpt.com "Why AI and robotics disruption is inevitable"
[28]: https://www.linkedin.com/posts/jeffreyemanuel_i-finally-got-around-to-trying-the-gemini-cli-activity-7377472083217362946-GogN?utm_source=chatgpt.com "Jeffrey Emanuel's Post"
[29]: https://x.com/doodlestein?s=21 "x.com"
[30]: https://github.com/Dicklesworthstone?tab=repositories "Dicklesworthstone (Dicklesworthstone) / Repositories · GitHub"
[31]: https://www.linkedin.com/in/jeffreyemanuel?utm_source=chatgpt.com "Jeffrey Emanuel - Founder and CEO at Pastel Network"
